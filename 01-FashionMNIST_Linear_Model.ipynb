{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 01 - Import Libraries\n",
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import numpy as np\n",
    "import PIL\n",
    "from torch.utils.data import DataLoader\n",
    "from timeit import default_timer as timer\n",
    "from tqdm.auto import tqdm\n",
    "RANDOM_SEED = torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary Functions\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "def accuracy_fn(y_true, y_pred):\n",
    "    correct = torch.eq(y_true, y_pred).sum().item()\n",
    "    acc = (correct / len(y_pred)) * 100\n",
    "    return acc\n",
    "def train_timer(start:float, end:float, device: torch.device=None):\n",
    "    total_time = end-start\n",
    "    print(f\"Device:{device}:{total_time:.2f}sec\")\n",
    "    return total_time\n",
    "\n",
    "def eval_model(model: torch.nn.Module,\n",
    "               data_loader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               accuracy_fn):\n",
    "    model.eval()\n",
    "    total_loss, total_acc = 0, 0\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for img, labels in tqdm(data_loader):\n",
    "            img, labels = img.to(device), labels.to(device)  \n",
    "            preds = model(img)\n",
    "            loss = loss_fn(preds, labels)\n",
    "            acc = accuracy_fn(labels, preds.argmax(dim=1))\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            total_acc += acc\n",
    "\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    avg_acc = total_acc / len(data_loader)\n",
    "\n",
    "    return {\n",
    "        \"model_name\": model.__class__.__name__,\n",
    "        \"model_loss\": avg_loss,\n",
    "        \"model_acc\": avg_acc\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 02 - Datasets\n",
    "train_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    "    target_transform= None,\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    "    target_transform= None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 03 - DataLoad\n",
    "class_names = train_data.classes\n",
    "train_dataloader = DataLoader(dataset=train_data,\n",
    "                              batch_size=32,\n",
    "                              shuffle=True)\n",
    "\n",
    "test_dataloader = DataLoader(dataset=test_data,\n",
    "                              batch_size=32,\n",
    "                              shuffle=False)\n",
    "train_features_batch, train_labels_batch = next(iter(train_dataloader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FashionMNISTModelV0(\n",
       "  (layer_stack): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=784, out_features=10, bias=True)\n",
       "    (2): Linear(in_features=10, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 04 - Linear Model \n",
    "class FashionMNISTModelV0(nn.Module):\n",
    "    def __init__(self, input_shape:int, hidden_units:int, output_shape:int):\n",
    "        super().__init__()\n",
    "        self.layer_stack = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=input_shape, out_features=hidden_units),\n",
    "            nn.Linear(in_features=hidden_units, out_features=output_shape))\n",
    "    def forward(self, x):\n",
    "        return self.layer_stack(x)\n",
    "\n",
    "model_0 = FashionMNISTModelV0(\n",
    "    input_shape=28*28,\n",
    "    hidden_units=10,\n",
    "    output_shape=len(class_names)\n",
    ")\n",
    "model_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05 - Loss Fnc. & Optimizer\n",
    "loss_fn0 = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params=model_0.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48ea8c8938bb4d76a3b21bb0f22d2f3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looked at: 0/60000 samples\n",
      "Looked at: 12800/60000 samples\n",
      "Looked at: 25600/60000 samples\n",
      "Looked at: 38400/60000 samples\n",
      "Looked at: 51200/60000 samples\n",
      "Train Loss: 0.5932 | Test Loss: 0.4972 | Test Acc: 82.3882\n",
      "Epoch: 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a34e7d08337b4477a93785c2cdaf17c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looked at: 0/60000 samples\n",
      "Looked at: 12800/60000 samples\n",
      "Looked at: 25600/60000 samples\n",
      "Looked at: 38400/60000 samples\n",
      "Looked at: 51200/60000 samples\n",
      "Train Loss: 0.4807 | Test Loss: 0.4978 | Test Acc: 82.1785\n",
      "Epoch: 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b7c862e9310486d963d1178f6f5c846",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looked at: 0/60000 samples\n",
      "Looked at: 12800/60000 samples\n",
      "Looked at: 25600/60000 samples\n",
      "Looked at: 38400/60000 samples\n",
      "Looked at: 51200/60000 samples\n",
      "Train Loss: 0.4560 | Test Loss: 0.4928 | Test Acc: 82.9573\n",
      "Device:cpu:131.91sec\n"
     ]
    }
   ],
   "source": [
    "# 06 - Training & Testing\n",
    "RANDOM_SEED\n",
    "train_time_start = timer()\n",
    "epochs = 3\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch: {epoch + 1}\")\n",
    "    model_0.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for batch, (img, labels) in enumerate(tqdm(train_dataloader)):\n",
    "        img, labels = img.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        train_preds = model_0(img)\n",
    "        train_loss = loss_fn0(train_preds, labels)\n",
    "        epoch_loss += train_loss.item()\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 400 == 0:\n",
    "            seen = batch * len(img)\n",
    "            total = len(train_dataloader.dataset)\n",
    "            print(f\"Looked at: {seen}/{total} samples\")\n",
    "\n",
    "    epoch_loss /= len(train_dataloader)\n",
    "\n",
    "    # Testing\n",
    "    model_0.eval()\n",
    "    test_loss, test_acc = 0, 0\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for img, labels in test_dataloader:\n",
    "            img, labels = img.to(device), labels.to(device)\n",
    "\n",
    "            test_preds = model_0(img)\n",
    "            test_loss += loss_fn0(test_preds, labels).item()\n",
    "            test_acc += accuracy_fn(labels, test_preds.argmax(dim=1))\n",
    "\n",
    "    test_loss /= len(test_dataloader)\n",
    "    test_acc /= len(test_dataloader)\n",
    "\n",
    "    print(f\"Train Loss: {epoch_loss:.4f} | Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.4f}\")\n",
    "\n",
    "train_time_end = timer()\n",
    "total_train_time_model_0 = train_timer(train_time_start, train_time_end, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5633d76e1bd24af4b0b6c6588feb5723",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'model_name': 'FashionMNISTModelV0',\n",
       " 'model_loss': 0.49280303545272386,\n",
       " 'model_acc': 82.95726837060703}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 07 - Result Evaluation\n",
    "RANDOM_SEED\n",
    "model_0_results = eval_model(model_0, test_dataloader, loss_fn0, accuracy_fn)\n",
    "model_0_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to model_0.pth\n"
     ]
    }
   ],
   "source": [
    "# 08 - Saving the model\n",
    "torch.save(model_0.state_dict(), \"Models/model_0.pth\")\n",
    "print(\"Model saved to model_0.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
